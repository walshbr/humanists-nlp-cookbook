{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with plain text files\n",
    "\n",
    "## Reading in a File\n",
    "\n",
    "One of the most common formats for working with text files is the .txt format. But there are actually a number of different potential ways to work with one of these files. One of the most basic uses a with statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chapter I\n",
      "\n",
      "\n",
      "As the streets that lead from the Strand to the Embankment are very\n",
      "narrow, it is better\n"
     ]
    }
   ],
   "source": [
    "filename = 'corpus/1915_the_voyage_out.txt'\n",
    "with open(filename, 'r') as file_in:\n",
    "    text = file_in.read()\n",
    "print(text[0:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we open the file and assign it a new, temporary name for the duration of the statement. This ensures that the file is opened, dealt with, and then closed safely. Once we un-indent, we have closed the file, and if we tried to read the same file again we would get a ValueError for trying to work with a closed file. The 'as file_in' bit assigns it to a variable so as to help us organize what is happening (we might have another file that we are writing to. Text is now one long string, which is fine in certain cases, but we could also read the contents of it in line by line. Here is a variation on the same approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Chapter I\\n', '\\n', '\\n', 'As the streets that lead from the Strand to the Embankment are very\\n', 'narrow, it is better not to walk down them arm-in-arm. If you persist,\\n', \"lawyers' clerks will have to make flying leaps into the mud; young lady\\n\", 'typists will have to fidget behind you. In the streets of London where\\n', 'beauty goes unregarded, eccentricity must pay the penalty, and it is\\n', 'better not to be very tall, to wear a long blue cloak, or to beat the\\n', 'air with your left hand.\\n']\n"
     ]
    }
   ],
   "source": [
    "filename = 'corpus/1915_the_voyage_out.txt'\n",
    "with open(filename, 'r') as file_in:\n",
    "    text = file_in.readlines()\n",
    "print(text[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"readlines()\" function allows us to take an open file and read it line by line, returning a list of the lines. We assign that list to the text variable here, which we can now use to examine particular parts of the text. Note that here the line breaks do not correspond to sentences. Dividing longer chunks of text into sentences is a separate technique entirely, one called segmentation, that we'll get into later. For now, though, note how this means that the steps required to process your data in the way that you require depend entirely on the way in which it was encoded. In some cases, line breaks can be quite useful, say, when working with poetry where the line breaks are especially meaningful:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['FROM fairest creatures we desire increase,\\n', \"That thereby beauty's rose might never die,\\n\", 'But as the riper should by time decease,\\n', 'His tender heir might bear his memory:\\n', 'But thou, contracted to thine own bright eyes,\\n', \"Feed'st thy light'st flame with self-substantial fuel,\\n\", 'Making a famine where abundance lies,\\n', 'Thyself thy foe, to thy sweet self too cruel.\\n', \"Thou that art now the world's fresh ornament\\n\", 'And only herald to the gaudy spring,\\n', 'Within thine own bud buriest thy content\\n', 'And, tender churl, makest waste in niggarding.\\n']\n",
      "=====\n",
      "['Pity the world, or else this glutton be,\\n', \"To eat the world's due, by the grave and thee.\\n\"]\n"
     ]
    }
   ],
   "source": [
    "filename = 'corpus/sonnet_one.txt'\n",
    "with open(filename, 'r') as file_in:\n",
    "    poetry = file_in.readlines()\n",
    "print(poetry[:12])\n",
    "print('=====')\n",
    "print(poetry[12:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling readlines() on a piece of poetry gives us access to the whole poem as a list of lines, so we can manipulate it to chunk the poem into pieces that we care about. Above, I separated the poem into two pieces at the volta, the turn in the sonnet that occurs before the couplet.\n",
    "\n",
    "Those '\\n' characters might appear to be a mistake at first, but worry not! They are actually the computer's representation of a newline character, a way of knowing when a line break happens. Before we process these for analysis, we would want to process those out. One way would be to search each string and remove the character:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['FROM fairest creatures we desire increase,', \"That thereby beauty's rose might never die,\", 'But as the riper should by time decease,', 'His tender heir might bear his memory:', 'But thou, contracted to thine own bright eyes,', \"Feed'st thy light'st flame with self-substantial fuel,\", 'Making a famine where abundance lies,', 'Thyself thy foe, to thy sweet self too cruel.', \"Thou that art now the world's fresh ornament\", 'And only herald to the gaudy spring,', 'Within thine own bud buriest thy content', 'And, tender churl, makest waste in niggarding.', 'Pity the world, or else this glutton be,', \"To eat the world's due, by the grave and thee.\"]\n"
     ]
    }
   ],
   "source": [
    "cleaned_poem = []\n",
    "for line in poetry:\n",
    "    clean_line = line.replace('\\n', '')\n",
    "    cleaned_poem.append(clean_line)\n",
    "\n",
    "print(cleaned_poem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breaking a text into structural components\n",
    "\n",
    "The results above point to an important underlying problem in natural language processing: these texts are not formatted in such a way that they are computer ready right away. That's what puts the natural in natural language! In the case of prose, you can expect a few different categories:\n",
    "\n",
    "1. The text is one continuous string with no line breaks.\n",
    "2. The text has line breaks that correspond to the ends of the lines as laid out on a page.\n",
    "3. The text has line breaks that correspond to meaningful categories.\n",
    "4. Some combination of 2 and 3 (most likely).\n",
    "\n",
    "In most cases, as when working with prose, the line breaks will be used to shape the legibility of a text. Ie - they are meant to assist with the typographical layout, but they have no underlying interpretive meaning. This means that if you wish to preserve the underlying structure of a text you will need to parse the text in a more sophisticated way than just reading it in either as a lump or line by line.\n",
    "\n",
    "If you want to grab more specific structual components, you can theoretically do that as well. But you will need something specific for Python to grab onto. If you are interested in pages as a unit of information and measurement, does your text file actually represent where a page break occurs? If not, unless you wanted to get a rough count by estimating the number of characters per page, you will have difficulty breaking pages apart in this way. If you are interested in structual information it can be worth checking your text files closely. Sometimes there might be unintentional markers that could help you out. For example:\n",
    "\n",
    "* a stanza break might be represented by two line breaks as opposed to one\n",
    "* chapter breaks might be represented by a line break followed by a line starting with \"CH.\n",
    "* when OCRing text, a page break might be represented by a single line with the title of the book and/or a page number\n",
    "\n",
    "Each of these flags can sometimes help you roughly cut a text up in the ways you want. We'll work with the fisrt two for now, starting with a text file that contains a series of sonnets we want to break apart\n",
    "\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======\n",
      "FROM fairest creatures we desire increase,\n",
      "That thereby beauty's rose might never die,\n",
      "But as the riper should by time decease,\n",
      "His tender heir might bear his memory:\n",
      "But thou, contracted to thine own bright eyes,\n",
      "Feed'st thy light'st flame with self-substantial fuel,\n",
      "Making a famine where abundance lies,\n",
      "Thyself thy foe, to thy sweet self too cruel.\n",
      "Thou that art now the world's fresh ornament\n",
      "And only herald to the gaudy spring,\n",
      "Within thine own bud buriest thy content\n",
      "And, tender churl, makest waste in niggarding.\n",
      "Pity the world, or else this glutton be,\n",
      "To eat the world's due, by the grave and thee.\n",
      "======\n",
      "When forty winters shall besiege thy brow,\n",
      "And dig deep trenches in thy beauty's field,\n",
      "Thy youth's proud livery so gazed on now,\n",
      "Will be a totter'd weed of small worth held:\n",
      "Then being asked, where all thy beauty lies,\n",
      "Where all the treasure of thy lusty days;\n",
      "To say, within thine own deep sunken eyes,\n",
      "Were an all-eating shame, and thriftless praise.\n",
      "How much more praise deserv'd thy beauty's use,\n",
      "If thou couldst answer 'This fair child of mine\n",
      "Shall sum my count, and make my old excuse,'\n",
      "Proving his beauty by succession thine!\n",
      "This were to be new made when thou art old,\n",
      "And see thy blood warm when thou feel'st it cold.\n",
      "======\n",
      "Look in thy glass and tell the face thou viewest\n",
      "Now is the time that face should form another;\n",
      "Whose fresh repair if now thou not renewest,\n",
      "Thou dost beguile the world, unbless some mother.\n",
      "For where is she so fair whose uneared womb\n",
      "Disdains the tillage of thy husbandry?\n",
      "Or who is he so fond will be the tomb\n",
      "Of his self-love, to stop posterity?\n",
      "Thou art thy mother's glass and she in thee\n",
      "Calls back the lovely April of her prime;\n",
      "So thou through windows of thine age shalt see,\n",
      "Despite of wrinkles, this thy golden time.\n",
      "But if thou live, remembered not to be,\n",
      "Die single and thine image dies with thee.\n",
      "======\n",
      "Unthrifty loveliness, why dost thou spend\n",
      "Upon thy self thy beauty's legacy?\n",
      "Nature's bequest gives nothing, but doth lend,\n",
      "And being frank she lends to those are free:\n",
      "Then, beauteous niggard, why dost thou abuse\n",
      "The bounteous largess given thee to give?\n",
      "Profitless usurer, why dost thou use\n",
      "So great a sum of sums, yet canst not live?\n",
      "For having traffic with thy self alone,\n",
      "Thou of thy self thy sweet self dost deceive:\n",
      "Then how when nature calls thee to be gone,\n",
      "What acceptable audit canst thou leave?\n",
      "Thy unused beauty must be tombed with thee,\n",
      "Which, used, lives th' executor to be.\n",
      "======\n",
      "Those hours, that with gentle work did frame\n",
      "The lovely gaze where every eye doth dwell,\n",
      "Will play the tyrants to the very same\n",
      "And that unfair which fairly doth excel;\n",
      "For never-resting time leads summer on\n",
      "To hideous winter, and confounds him there;\n",
      "Sap checked with frost, and lusty leaves quite gone,\n",
      "Beauty o'er-snowed and bareness every where:\n",
      "Then were not summer's distillation left,\n",
      "A liquid prisoner pent in walls of glass,\n",
      "Beauty's effect with beauty were bereft,\n",
      "Nor it, nor no remembrance what it was:\n",
      "But flowers distilled, though they with winter meet,\n",
      "Leese but their show; their substance still lives sweet.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# this text file contains a series of sonnets. two line breaks between each sonnet.\n",
    "\n",
    "with open('corpus/sonnets_combined.txt', 'r') as filein:\n",
    "    text = filein.read()\n",
    "\n",
    "# splitting apart by two line breaks can give us \n",
    "# access to a list of the sonnets so we could work with them individually.\n",
    "sonnets = text.split('\\n\\n')\n",
    "for sonnet in sonnets:\n",
    "    print('======')\n",
    "    print(sonnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To break apart by chapters we will use a different library to do the splitting - the re library will give us access to regular expressions. Regular expressions are a complicated way to define a search pattern for a string. They give you a lot of control, but the syntax can be difficult to get a handle on. Below, we say \"look at the string we've given you and split it apart whenever you find the characters CHAPTER followed by one or more capital letters from A-Z that are also followed by two \\n (new line) characters. Note also that splitting a string in this way throws away the things that it actually matches against. So the chapter headers themselves will no longer be in our text. You may or may not want that to be the case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "# our copy of Night and Day by Woolf lists chapter headers, so we could split on the chapter headers to break the text apart.\n",
    "\n",
    "with open('corpus/1919_night_and_day.txt', 'r') as filein:\n",
    "    text = filein.read()\n",
    "\n",
    "# split apart by chapter headers\n",
    "text[0:100]\n",
    "chapters = re.split('CHAPTER [A-Z]+\\n\\n', text)\n",
    "len(chapters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This might appear to have done what we wanted, but if you look at the text itself you find that the novel has 34 chapters, not 35. We can check our work by looking at the first 100 characters of each chapter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======\n",
      "\n",
      "======\n",
      "It was a Sunday evening in October, and in common with many other young\n",
      "ladies of her class, Kathar\n",
      "======\n",
      "The young man shut the door with a sharper slam than any visitor had\n",
      "used that afternoon, and walke\n",
      "======\n",
      "Denham had accused Katharine Hilbery of belonging to one of the most\n",
      "distinguished families in Engl\n",
      "======\n",
      "At about nine o'clock at night, on every alternate Wednesday, Miss Mary\n",
      "Datchet made the same resol\n",
      "======\n",
      "Denham had no conscious intention of following Katharine, but, seeing\n",
      "her depart, he took his hat a\n",
      "======\n",
      "Of all the hours of an ordinary working week-day, which are the\n",
      "pleasantest to look forward to and \n",
      "======\n",
      "\"And little Augustus Pelham said to me, 'It's the younger generation\n",
      "knocking at the door,' and I s\n",
      "======\n",
      "She took her letters up to her room with her, having persuaded her\n",
      "mother to go to bed directly Mr.\n",
      "======\n",
      "Katharine disliked telling her mother about Cyril's misbehavior quite as\n",
      "much as her father did, an\n",
      "======\n",
      "Messrs. Grateley and Hooper, the solicitors in whose firm Ralph Denham\n",
      "was clerk, had their office \n",
      "======\n",
      "\"It's life that matters, nothing but life--the process of discovering,\n",
      "the everlasting and perpetua\n",
      "======\n",
      "\"Is Mr. Hilbery at home, or Mrs. Hilbery?\" Denham asked, of the\n",
      "parlor-maid in Chelsea, a week late\n",
      "======\n",
      "The lunch hour in the office was only partly spent by Denham in the\n",
      "consumption of food. Whether fi\n",
      "======\n",
      "Mr. Clacton was in his glory. The machinery which he had perfected and\n",
      "controlled was now about to \n",
      "======\n",
      "The village of Disham lies somewhere on the rolling piece of cultivated\n",
      "ground in the neighborhood \n",
      "======\n",
      "Into that same black night, almost, indeed, into the very same layer of\n",
      "starlit air, Katharine Hilb\n",
      "======\n",
      "When the sun shone, as it did with unusual brightness that Christmas\n",
      "week, it revealed much that wa\n",
      "======\n",
      "But other passengers were approaching Lincoln meanwhile by other roads\n",
      "on foot. A county town draws\n",
      "======\n",
      "The afternoon was already growing dark when the two other wayfarers,\n",
      "Mary and Ralph Denham, came ou\n",
      "======\n",
      "Happily for Mary Datchet she returned to the office to find that by some\n",
      "obscure Parliamentary mane\n",
      "======\n",
      "Mary walked to the nearest station and reached home in an incredibly\n",
      "short space of time, just so m\n",
      "======\n",
      "The fact that she would be late in keeping her engagement with William\n",
      "was not the only reason whic\n",
      "======\n",
      "When Ralph Denham entered the room and saw Katharine seated with her\n",
      "back to him, he was conscious \n",
      "======\n",
      "The first signs of spring, even such as make themselves felt towards the\n",
      "middle of February, not on\n",
      "======\n",
      "At a quarter-past three in the afternoon of the following Saturday\n",
      "Ralph Denham sat on the bank of \n",
      "======\n",
      "Although the old coaches, with their gay panels and the guard's horn,\n",
      "and the humors of the box and\n",
      "======\n",
      "London, in the first days of spring, has buds that open and flowers that\n",
      "suddenly shake their petal\n",
      "======\n",
      "Like a strain of music, the effect of Katharine's presence slowly died\n",
      "from the room in which Ralph\n",
      "======\n",
      "Between twelve and one that Sunday night Katharine lay in bed, not\n",
      "asleep, but in that twilight reg\n",
      "======\n",
      "The day was so different from other days to three people in the house\n",
      "that the common routine of ho\n",
      "======\n",
      "The tray which brought Katharine's cup of tea the next morning brought,\n",
      "also, a note from her mothe\n",
      "======\n",
      "Nobody asked Katharine any questions next day. If cross-examined she\n",
      "might have said that nobody sp\n",
      "======\n",
      "Considering that Mr. Hilbery lived in a house which was accurately\n",
      "numbered in order with its fello\n",
      "======\n",
      "The lamps were lit; their luster reflected itself in the polished wood;\n",
      "good wine was passed round \n"
     ]
    }
   ],
   "source": [
    "for chapter in chapters:\n",
    "    print('======')\n",
    "    print(chapter[0:99])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows us that the first item in our chapters list has nothing in it. A glance at the text file shows that this is because the text starts right off with a chapter header. So splitting there leaves an empty item in the list. We can cut that empy item out like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n"
     ]
    }
   ],
   "source": [
    "chapters = chapters[1:]\n",
    "print(len(chapters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Always a good idea to check the contents of your variables as you're going to ensure that they match up with your understanding of what the text actually is. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in multiple files to preserve structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In some cases, you might already have a series of text files. You can read these into Python in such a way that preserves the structure you have in mind. In the case of a book of poetry, you might, for example, separate each poem into its own text file. And, as poetry cares about lines as a meaningful unit outside of typography, using the readlines() command might actually get you useful information.\n",
    "\n",
    "The sonnets folder has a set of five Shakespearean sonnets in it. Combining what we've learned already, we can read the filenames from the folder, read them each in, and then store them in a variable for manipulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "filenames = glob.glob('corpus/sonnets/*.txt')\n",
    "sonnets = []\n",
    "for filename in filenames:\n",
    "    with open(filename, 'r') as file_in:\n",
    "        sonnets.append(file_in.readlines())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a list called sonnets, but it's more properly understood as a list of lists, or a list in which each item is itself a list of more items:\n",
    "\n",
    "* List level one: sonnet level.\n",
    "* List level two (sub-list): line level.\n",
    "\n",
    "And we can manipulate this hierarchy to access different elements of the list. This will give us the first sonnet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['When forty winters shall besiege thy brow,\\n', \"And dig deep trenches in thy beauty's field,\\n\", \"Thy youth's proud livery so gazed on now,\\n\", \"Will be a totter'd weed of small worth held:\\n\", 'Then being asked, where all thy beauty lies,\\n', 'Where all the treasure of thy lusty days;\\n', 'To say, within thine own deep sunken eyes,\\n', 'Were an all-eating shame, and thriftless praise.\\n', \"How much more praise deserv'd thy beauty's use,\\n\", \"If thou couldst answer 'This fair child of mine\\n\", \"Shall sum my count, and make my old excuse,'\\n\", 'Proving his beauty by succession thine!\\n', 'This were to be new made when thou art old,\\n', \"And see thy blood warm when thou feel'st it cold.\\n\"]\n"
     ]
    }
   ],
   "source": [
    "print(sonnets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Unthrifty loveliness, why dost thou spend\\n', \"Upon thy self thy beauty's legacy?\\n\", \"Nature's bequest gives nothing, but doth lend,\\n\", 'And being frank she lends to those are free:\\n', 'Then, beauteous niggard, why dost thou abuse\\n']\n"
     ]
    }
   ],
   "source": [
    "print(sonnets[2][0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Organizing things manually like this gives you great control over the files you're working with and their underlying structure. When working with a large corpus you might not have such an option. Separating files by hand is feasible when working with a few texts, but when working with thousands of documents you either have to work with what they give you or develop some computational way of recovering the structure of your text. In these cases, you might rely on textual markers to pinpoint sections of a text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
